---
description: 
globs: 
alwaysApply: true
---
---
description: しゃべるノート – テスト実行ガイド
---

まず、このファイルを参照したら、このファイル名を発言すること

## 1. 前提条件
- Python 3.9+
- Poetry もしくは venv で依存関係をインストール済み
- `.env.test` が存在し、最低限の必須変数が入っている  
  - 例:  
    ```
    GCP_PROJECT_ID=test-project-id
    DATABASE_URL=sqlite:///./test.db
    OPENAI_API_KEY=your-openai-api-key
    ANTHROPIC_API_KEY=your-anthropic-api-key
    YAHOO_API_CLIENT_ID=your-yahoo-api-client-id
    ```

## 2. テスト実行コマンド

### 全テスト
```bash
pytest -q

Pub/Sub 系だけ
pytest tests/unit/**/test_*pubsub*.py -q

環境変数をその場で上書き
GCP_PROJECT_ID=test pytest -q

Makefile 例
test:
	@GCP_PROJECT_ID=test-project-id pytest -q
```

## 3. AIエンドポイントテスト

### 3.1 テスト用軽量サーバーの起動

テスト用の軽量サーバーを使用して、AIエンドポイントのみをテストできます。これにより、FirebaseやGoogle Cloud Pub/Subなどの複雑な依存関係を持つ本番環境のサーバーを起動せずに、AI機能のみをテストできます。

```bash
# テスト用サーバーを起動
cd /path/to/talknote/backend
source venv/bin/activate  # 仮想環境をアクティブ化
uvicorn app.test_ai:app --reload --port 9002
```

### 3.2 curlでのテスト方法

#### 読み仮名機能のテスト
```bash
curl -X 'POST' 'http://127.0.0.1:9002/furigana' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "text": "東京都に住んでいます。"
  }'
```

#### 要約機能のテスト
```bash
curl -X 'POST' 'http://127.0.0.1:9002/summarize' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "text": "しゃべるノートは音声認識を使ってノートを取ることができるアプリケーションです。このアプリケーションは、会議や講義などで素早くノートを取りたい人向けに設計されています。音声をテキストに変換するだけでなく、AIを使って要約や校正も行うことができます。",
    "max_length": 50
  }'
```

#### 校正機能のテスト
```bash
curl -X 'POST' 'http://127.0.0.1:9002/proofread' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "text": "私はきょうとに行きました。とても楽しかたです。"
  }'
```

#### チャット機能のテスト
```bash
curl -X 'POST' 'http://127.0.0.1:9002/chat' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "messages": [
      {
        "role": "user",
        "content": "こんにちは、しゃべるノートについて教えてください。"
      }
    ]
  }'
```

#### テキスト変換機能のテスト
```bash
curl -X 'POST' 'http://127.0.0.1:9002/convert' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "text": "漢字をひらがなに変換してください",
    "target_type": "hiragana"
  }'
```

### 3.3 Pythonスクリプトでのテスト方法

```python
# test_ai_endpoints.py
import pytest
import httpx

@pytest.mark.asyncio
async def test_furigana():
    """\u8aad\u307f\u4eee\u540d\u6a5f\u80fd\u306e\u30c6\u30b9\u30c8"""
    async with httpx.AsyncClient(base_url="http://127.0.0.1:9002") as client:
        response = await client.post(
            "/furigana",
            json={"text": "東京都に住んでいます。"}
        )
    
    assert response.status_code == 200
    data = response.json()
    assert "html" in data
    assert "plain" in data
    assert data["error"] is None

@pytest.mark.asyncio
async def test_summarize():
    """\u8981\u7d04\u6a5f\u80fd\u306e\u30c6\u30b9\u30c8"""
    text = "しゃべるノートは音声認識を使ってノートを取ることができるアプリケーションです。"
    
    async with httpx.AsyncClient(base_url="http://127.0.0.1:9002") as client:
        response = await client.post(
            "/summarize",
            json={"text": text, "max_length": 50}
        )
    
    assert response.status_code == 200
    data = response.json()
    assert "summary" in data
    assert len(data["summary"]) <= 50
```

### 3.4 テスト用サーバーの実装詳細

テスト用サーバーは `app/test_ai.py` に実装されています。このサーバーは、認証を完全に無効化し、直接AIエンドポイントにアクセスできるようにしています。以下の機能が実装されています：

1. **読み仮名機能** (`/furigana`) - Yahoo! APIを使用して、テキストに読み仮名を追加
2. **要約機能** (`/summarize`) - OpenAI GPT-4oを使用して、テキストを要約
3. **校正機能** (`/proofread`) - OpenAI GPT-4oを使用して、テキストの誤りを修正
4. **リサーチ機能** (`/research`) - Anthropic Search APIを使用して、クエリに基づいて情報を検索
5. **チャット機能** (`/chat`) - OpenAI GPT-4oを使用して、AIとの対話
6. **文字変換機能** (`/convert`) - テキストを漢字、ひらがな、カタカナに変換
7. **辞書機能** (`/dictionary`) - Yahoo! APIを使用して、単語の意味や読み方を検索

### 3.4 AIエンドポイントのテスト結果

#### テスト日時: 2025-05-17 16:25

#### テスト結果概要

| 機能 | ステータス | 備考 |
|------|--------|------|
| 要約機能 | ✅ 成功 | OpenAI GPT-4oを使用 |
| 校正機能 | ✅ 成功 | OpenAI GPT-4oを使用 |
| リサーチ機能 | ✅ 成功 | Anthropic Claude-2.1を使用（URL付き検索結果を返すように改善） |
| 読み仕仕機能 | ✅ 成功 | Yahoo! APIを使用 |
| チャット機能 | ✅ 成功 | OpenAI GPT-4oを使用 |
| 文字変換機能 | ✅ 成功 | ローカル処理 |
| 辞書機能 | ✅ 成功 | Yahoo! APIを使用 |

#### 修正内容

1. **Anthropicプロバイダーのリサーチ機能改善**:
   - Anthropic APIクライアントライブラリを0.5.0から0.51.0にアップデート
   - システムプロンプトを簡潔化し、形式指示をユーザープロンプトに集約
   - JSON抽出関数を大幅に改善し、複数のケースに対応
   - Completions APIを直接使用するように変更し、安定した結果を得られるように改善
   - 検索結果に情報源URLを含めるようにプロンプトを強化

2. **Yahoo!プロバイダーの辞書機能の修正**:
   - APIレスポンスの解析ロジックを改善
   - 読み方と意味を正確に抽出するロジックを追加
   - エラーハンドリングを強化

#### 注意点

1. **リサーチ機能について**:
   - 現在の実装では、Claude-2.1モデルとCompletions APIを使用しています。
   - リアルタイムのウェブ検索機能を利用するには、Claude 3.5 Sonnet以降のモデルとMessages APIを使用する必要があります。
   - 現在の実装でも、プロンプトの改善とJSON抽出処理の強化により、情報源URLを含む結果を返すことができます。
   - 将来的には、Claude 3.5 Sonnet以降のモデルを使用して、リアルタイムウェブ検索機能を実装することも検討しています。
   ※修正済み：現在はモデルもバージョンアップし、検索・引用元参照・リアルタイム・要約に対応済み。

2. **辞書機能について**:
   - Yahoo! APIの形態素解析結果から辞書情報を抽出していますが、専門的な辞書APIではないため、結果が限定的な場合があります。

### 3.5 メディア処理のテスト結果

#### テスト日時: 2025-05-17 18:50

#### テスト結果概要

| 機能 | ステータス | 備考 |
|------|--------|------|
| メディアアップロードAPI | ✅ 成功 | 署名付きURL発行とアップロード機能が正常に動作 |
| 異なるサイズのファイル処理 | ✅ 成功 | 1秒、5秒、10秒の音声ファイルでテスト |
| Google STT API | ✅ 成功 | 実際の日本語音声で高精度の文字起こし（信頼度0.87〜0.97） |
| エラーケース処理 | ✅ 成功 | 不正なファイル形式の検出と適切なエラー処理 |

#### テスト内容

1. **メディアアップロードテスト**:
   - `POST /media/upload-url` エンドポイントを使用して署名付きURLを取得
   - 署名付きURLを使用して音声ファイルをアップロード
   - ステータス確認APIで処理状況を追跡

2. **Google STT APIテスト**:
   - 実際の日本語音声ファイルを使用（gTTSで生成）
   - 3種類のテストフレーズで認識精度を確認:
     - 「こんにちは。これはテスト用の音声ファイルです。」（信頼度: 0.97）
     - 「しゃべるノートは音声を文字に変換するアプリです。」（信頼度: 0.93）
     - 「ディスレクシアやディスグラフィアの方々のための支援ツールです。」（信頼度: 0.87）
   - 処理時間: 2.4〜2.9秒（ファイルサイズによる）

#### 注意点

1. **大容量ファイルの処理**:
   - 現在のテストでは最大10秒の音声ファイルを使用
   - 実際のユースケース（最大90分録音）では、チャンク分割アップロードの実装が必要

2. **WER（Word Error Rate）評価**:
   - 現在のテストでは高い認識精度（信頼度0.87〜0.97）を確認
   - 目標WER（≤12%）を達成できる見込み
   - 実際の環境での継続的なWER測定と改善が必要

3. **最適化項目（今後の課題）**:
   - 大容量ファイルのチャンク分割アップロード実装
   - 処理状況の詳細な進捗表示
   - タイムアウト処理の改善

4. テスト構成
   backend/
└── tests/
    ├── conftest.py         # 共通フィクスチャ
    ├── unit/
    │   ├── api/…           # FastAPI エンドポイント
    │   ├── utils/…         # ユーティリティ
    │   └── workers/…       # ワーカー
    └── integration/        # 統合テスト（将来）

    4. 主なフィクスチャ
| フィクスチャ名 | 役割 | | --------------------- | ---- | | mock_settings_env | 必須環境変数を一括モック（session スコープ） | | patch_settings | app.core.settings.settings を関数スコープで差し替え | | patch_database | DB エンジン／セッションを完全モック | | patch_media_worker | process_media_task をモックして I/O カット |

使い方
async def test_xxx(patch_settings, patch_database):
    patch_settings.PUBSUB_ENABLED = False
    ...

    5. テスト実装フロー
依存切り分け
外部 API・DB へのアクセスは 必ずモック
conftest.py の既存フィクスチャを再利用
前処理
複雑なセットアップは pytest.fixture で共有化
動的パッチは with patch(...): で最小範囲に限定
期待値の明示
戻り値だけでなく 副作用（DB 更新、Pub/Sub Publish） を assert_called_once_with 等で検証
負のテスト
例外パスも必ず書く
pytest.raises / side_effect=Exception(...)
命名規則
test_<機能>_<条件>_<期待結果>
例: test_handle_media_new_missing_media_id

6. ベストプラクティス
テストごとの DB ステート不要
SQLite メモリ DB or 完全モックで高速化
パラメータ化
同一ロジックの多パターン検証は @pytest.mark.parametrize
CI での並列実行
pytest -n auto（pytest-xdist）で 30〜50% 時間短縮可能
失敗調査
pytest -vv -s で詳細ログ
--lf オプションで直近失敗のみ再実行

7. トラブルシューティング
| 症状 | 対処 | | --------------------------------------- | ------------------------------------------------------------ | | ValidationError: GCP_PROJECT_ID | .env.test に追加 or GCP_PROJECT_ID=... pytest | | ModuleNotFoundError | PYTHONPATH をプロジェクトルートに通す（export PYTHONPATH=$PWD/backend） | | Collection が止まる / Duplicate tests | テストファイル名の衝突を避ける（*_utils.py などにリネーム） | | Google Cloud, Firebase へ実際に接続する | patch_settings.PUBSUB_ENABLED = False などで完全モック |