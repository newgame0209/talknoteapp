"""
Google Vision API OCR Provider

Google Cloud Vision APIã‚’ä½¿ç”¨ã—ã¦OCRï¼ˆå…‰å­¦æ–‡å­—èªè­˜ï¼‰ã‚’å®Ÿè¡Œã™ã‚‹ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã™ã€‚
é«˜ç²¾åº¦ãªæ—¥æœ¬èªãƒ»è‹±èªã®æ–‡å­—èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
"""

import logging
from typing import Dict, List, Optional, Any
import io
import numpy as np
import os
import uuid

try:
    from google.cloud import vision
    from google.api_core import exceptions as gcp_exceptions
    GOOGLE_VISION_AVAILABLE = True
except ImportError:
    GOOGLE_VISION_AVAILABLE = False
    vision = None
    gcp_exceptions = None

try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False
    cv2 = None

from .base import OCRProvider, OCRResult, OCRError

logger = logging.getLogger(__name__)


class GoogleVisionOCRProvider(OCRProvider):
    """Google Vision APIã‚’ä½¿ç”¨ã—ãŸOCRãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""
    
    def __init__(self, **kwargs):
        """
        Google Vision OCRãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–
        
        Args:
            **kwargs: è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                - project_id: Google Cloud ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
                - credentials_path: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ã®ãƒ‘ã‚¹
        """
        super().__init__(**kwargs)
        
        if not GOOGLE_VISION_AVAILABLE:
            raise OCRError(
                "Google Cloud Vision library is not available. "
                "Install with: pip install google-cloud-vision",
                provider="google_vision"
            )
        
        if not OPENCV_AVAILABLE:
            logger.warning("OpenCV is not available. Image preprocessing will be limited.")
        
        try:
            # Vision APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
            self.client = vision.ImageAnnotatorClient()
            logger.info("Google Vision OCR Provider initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Google Vision client: {e}")
            raise OCRError(
                f"Failed to initialize Google Vision client: {e}",
                provider="google_vision"
            )
    
    def _preprocess_image(self, image_bytes: bytes) -> bytes:
        """
        MVPã®æˆåŠŸä¾‹ã«åŸºã¥ãç”»åƒå‰å‡¦ç†
        æ‰‹æ›¸ãæ–‡å­—èªè­˜ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®å‡¦ç†ã‚’å®Ÿè¡Œ
        
        Args:
            image_bytes: å…ƒã®ç”»åƒãƒ‡ãƒ¼ã‚¿
            
        Returns:
            bytes: å‰å‡¦ç†æ¸ˆã¿ç”»åƒãƒ‡ãƒ¼ã‚¿
        """
        logger.info(f"ğŸ”§ _preprocess_image called with {len(image_bytes)} bytes")
        
        if not OPENCV_AVAILABLE:
            logger.warning("OpenCV not available, skipping image preprocessing")
            return image_bytes
        
        logger.info("ğŸ”§ OpenCV is available, starting preprocessing")
        try:
            # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
            debug_dir = os.getenv("HANDWRITING_DEBUG_DIR", "/tmp/handwriting_debug")
            debug_id = str(uuid.uuid4())
            logger.info(f"ğŸ”§ Debug directory: {debug_dir}, Debug ID: {debug_id}")
            
            # ãƒ‡ãƒãƒƒã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            os.makedirs(debug_dir, exist_ok=True)
            
            # 1. ãƒã‚¤ãƒˆé…åˆ—ã‚’numpyé…åˆ—ã«å¤‰æ›
            nparr = np.frombuffer(image_bytes, np.uint8)
            
            # ğŸ”§ RGBAå¯¾å¿œ: ã‚¢ãƒ«ãƒ•ã‚¡ãƒãƒ£ãƒ³ãƒãƒ«ä»˜ãã§èª­ã¿è¾¼ã¿
            image = cv2.imdecode(nparr, cv2.IMREAD_UNCHANGED)
            
            if image is None:
                logger.error("Failed to decode image with OpenCV")
                return image_bytes
            
            logger.info(f"ğŸ“¸ Original image shape: {image.shape}")
            
            # ğŸ”§ RGBAâ†’RGBå¤‰æ›ï¼ˆé€æ˜èƒŒæ™¯ã‚’ç™½èƒŒæ™¯ã«å¤‰æ›ï¼‰
            if len(image.shape) == 3 and image.shape[2] == 4:
                # RGBAç”»åƒã®å ´åˆ
                logger.info("ğŸ“¸ Converting RGBA to RGB with white background")
                
                # ã‚¢ãƒ«ãƒ•ã‚¡ãƒãƒ£ãƒ³ãƒãƒ«ã‚’åˆ†é›¢
                bgr = image[:, :, :3]
                alpha = image[:, :, 3:4] / 255.0
                
                # ç™½èƒŒæ™¯ã‚’ä½œæˆ
                white_background = np.ones_like(bgr, dtype=np.uint8) * 255
                
                # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆé€æ˜éƒ¨åˆ†ã‚’ç™½èƒŒæ™¯ã§åŸ‹ã‚ã‚‹ï¼‰
                image = (bgr * alpha + white_background * (1 - alpha)).astype(np.uint8)
                
                logger.info(f"ğŸ“¸ RGBAâ†’RGB conversion completed: {image.shape}")
            elif len(image.shape) == 3 and image.shape[2] == 3:
                # æ—¢ã«BGRç”»åƒã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
                logger.info("ğŸ“¸ Image is already BGR format")
            else:
                # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã®å ´åˆã¯BGRã«å¤‰æ›
                if len(image.shape) == 2:
                    image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
                    logger.info("ğŸ“¸ Converted grayscale to BGR")
            
            # ãƒ‡ãƒãƒƒã‚°: RGBå¤‰æ›å¾Œã®ç”»åƒã‚’ä¿å­˜
            try:
                rgb_path = os.path.join(debug_dir, f"{debug_id}_00_rgb_converted.png")
                cv2.imwrite(rgb_path, image)
                logger.info(f"ğŸ“¸ Saved RGB converted image: {rgb_path}")
            except Exception as e:
                logger.warning(f"Could not save RGB debug image: {e}")
            
            # 2. ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # ãƒ‡ãƒãƒƒã‚°: ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã‚’ä¿å­˜
            try:
                gray_path = os.path.join(debug_dir, f"{debug_id}_01_gray.png")
                cv2.imwrite(gray_path, gray)
                logger.info(f"ğŸ“¸ Saved grayscale image: {gray_path}")
            except Exception as e:
                logger.warning(f"Could not save grayscale debug image: {e}")
            
            # 3. ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã§ãƒã‚¤ã‚ºé™¤å»
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # 4. é©å¿œçš„äºŒå€¤åŒ–ï¼ˆMVPã®æˆåŠŸä¾‹ï¼‰
            binary = cv2.adaptiveThreshold(
                blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
            )
            
            # ãƒ‡ãƒãƒƒã‚°: äºŒå€¤åŒ–ç”»åƒã‚’ä¿å­˜
            try:
                binary_path = os.path.join(debug_dir, f"{debug_id}_02_binary.png")
                cv2.imwrite(binary_path, binary)
                logger.info(f"ğŸ“¸ Saved binary image: {binary_path}")
            except Exception as e:
                logger.warning(f"Could not save binary debug image: {e}")
            
            # 5. å½¢æ…‹å­¦çš„å‡¦ç†ï¼ˆãƒã‚¤ã‚ºé™¤å»ã¨æ–‡å­—ã®è£œå¼·ï¼‰
            kernel = np.ones((2, 2), np.uint8)
            
            # ãƒã‚¤ã‚ºé™¤å»ï¼ˆopeningï¼‰
            opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
            
            # æ–‡å­—ã®è£œå¼·ï¼ˆclosingï¼‰
            processed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
            
            # ãƒ‡ãƒãƒƒã‚°: æœ€çµ‚å‡¦ç†ç”»åƒã‚’ä¿å­˜
            try:
                final_path = os.path.join(debug_dir, f"{debug_id}_03_final.png")
                cv2.imwrite(final_path, processed)
                logger.info(f"ğŸ“¸ Saved final processed image: {final_path}")
            except Exception as e:
                logger.warning(f"Could not save final debug image: {e}")
            
            # 6. å‡¦ç†æ¸ˆã¿ç”»åƒã‚’ãƒã‚¤ãƒˆé…åˆ—ã«å¤‰æ›
            success, encoded_image = cv2.imencode('.png', processed)
            if not success:
                logger.error("Failed to encode processed image")
                return image_bytes
            
            processed_bytes = encoded_image.tobytes()
            logger.info(f"ğŸ“¸ Image preprocessing completed: {len(image_bytes)} -> {len(processed_bytes)} bytes")
            
            return processed_bytes
            
        except Exception as e:
            logger.error(f"Image preprocessing failed: {e}")
            return image_bytes

    async def extract_text(
        self, 
        image_data: bytes, 
        language_hints: Optional[List[str]] = None,
        desired_rotation: Optional[int] = None
    ) -> OCRResult:
        """
        Google Vision APIã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        
        Args:
            image_data: ç”»åƒã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿
            language_hints: è¨€èªãƒ’ãƒ³ãƒˆï¼ˆä¾‹: ['ja', 'en']ï¼‰
            desired_rotation: ç”»åƒã®å›è»¢è§’åº¦ï¼ˆ90, 180, 270åº¦ï¼‰- æ¨ªå‘ãç”»åƒã®OCRç²¾åº¦å‘ä¸Šç”¨
            
        Returns:
            OCRResult: æŠ½å‡ºçµæœ
        """
        try:
            # ğŸ”§ ç”»åƒå‰å‡¦ç†ã‚’æœ‰åŠ¹åŒ–ï¼ˆRGBAâ†’RGBå¤‰æ›ã‚’å«ã‚€ï¼‰
            logger.info(f"ğŸ”§ Starting image preprocessing for {len(image_data)} bytes")
            processed_image_data = self._preprocess_image(image_data)
            logger.info(f"ğŸ”§ Image preprocessing completed: {len(processed_image_data)} bytes")
            
            # Vision APIç”¨ã®ç”»åƒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            image = vision.Image(content=processed_image_data)
            
            # ç”»åƒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
            image_context = None
            context_params = {}
            
            # è¨€èªãƒ’ãƒ³ãƒˆã‚’è¨­å®š
            if language_hints:
                context_params['language_hints'] = language_hints
                logger.info(f"ğŸ” Using language hints: {language_hints}")
            
            # ğŸ†• desired_rotationã‚’è¨­å®šï¼ˆæ¨ªå‘ãç”»åƒå¯¾å¿œï¼‰
            if desired_rotation is not None:
                context_params['desired_rotation'] = desired_rotation
                logger.info(f"ğŸ”„ Using desired rotation: {desired_rotation} degrees")
            
            # ImageContextã‚’ä½œæˆï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
            if context_params:
                image_context = vision.ImageContext(**context_params)
            
            # MVPã¨åŒã˜document_text_detectionã‚’ä½¿ç”¨ï¼ˆé«˜ç²¾åº¦ï¼‰
            if image_context:
                response = self.client.document_text_detection(
                    image=image, 
                    image_context=image_context
                )
            else:
                response = self.client.document_text_detection(image=image)
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            if response.error.message:
                raise OCRError(
                    f"Google Vision API error: {response.error.message}",
                    provider="google_vision",
                    error_code=str(response.error.code)
                )
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆæ³¨é‡ˆã‚’å–å¾—
            if response.full_text_annotation:
                full_text = response.full_text_annotation.text
                logger.info(f"ğŸ” Document text detected: '{full_text}'")
                
                # ä¿¡é ¼åº¦ã‚’è¨ˆç®—
                confidence = 0.9  # document_text_detectionã¯é«˜ç²¾åº¦
                
                # è¨€èªæ¤œå‡º
                detected_language = self._detect_language(full_text)
                
                return OCRResult(
                    text=full_text,
                    confidence=confidence,
                    language=detected_language,
                    metadata={
                        "provider": "google_vision",
                        "method": "document_text_detection",
                        "preprocessed": OPENCV_AVAILABLE
                    }
                )
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®text_detection
            texts = response.text_annotations
            
            if not texts:
                # ãƒ†ã‚­ã‚¹ãƒˆãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆ
                logger.warning("ğŸ” No text detected in image")
                return OCRResult(
                    text="",
                    confidence=0.0,
                    language=None,
                    metadata={"provider": "google_vision", "texts_count": 0}
                )
            
            # æœ€åˆã®è¦ç´ ãŒå…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆ
            full_text = texts[0].description
            logger.info(f"ğŸ” Text detected: '{full_text}'")
            
            # ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆå€‹åˆ¥ã®æ–‡å­—ã®ä¿¡é ¼åº¦ã®å¹³å‡ï¼‰
            total_confidence = 0.0
            confidence_count = 0
            
            # å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹æƒ…å ±ã‚’åé›†
            bounding_boxes = []
            
            for text in texts[1:]:  # æœ€åˆã®è¦ç´ ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå…¨ä½“ãƒ†ã‚­ã‚¹ãƒˆï¼‰
                # å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹æƒ…å ±ã‚’è¿½åŠ 
                vertices = text.bounding_poly.vertices
                bounding_box = {
                    "text": text.description,
                    "vertices": [
                        {"x": vertex.x, "y": vertex.y} 
                        for vertex in vertices
                    ]
                }
                bounding_boxes.append(bounding_box)
            
            # è¨€èªæ¤œå‡º
            detected_language = self._detect_language(full_text)
            
            # ä¿¡é ¼åº¦ã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            confidence = min(0.95, len(full_text.strip()) / max(1, len(full_text)) * 0.9 + 0.1)
            
            return OCRResult(
                text=full_text,
                confidence=confidence,
                language=detected_language,
                bounding_boxes=bounding_boxes,
                metadata={
                    "provider": "google_vision",
                    "method": "text_detection",
                    "texts_count": len(texts),
                    "has_bounding_boxes": len(bounding_boxes) > 0,
                    "preprocessed": OPENCV_AVAILABLE
                }
            )
            
        except gcp_exceptions.GoogleAPIError as e:
            logger.error(f"Google Vision API error: {e}")
            raise OCRError(
                f"Google Vision API error: {e}",
                provider="google_vision",
                error_code=str(e.code) if hasattr(e, 'code') else None
            )
        except Exception as e:
            logger.error(f"Unexpected error in Google Vision OCR: {e}")
            raise OCRError(
                f"Unexpected error in Google Vision OCR: {e}",
                provider="google_vision"
            )
    
    def is_available(self) -> bool:
        """
        Google Vision APIãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        
        Returns:
            bool: åˆ©ç”¨å¯èƒ½ãªå ´åˆTrue
        """
        if not GOOGLE_VISION_AVAILABLE:
            return False
        
        try:
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
            # å®Ÿéš›ã«ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ãŒæˆåŠŸã—ã¦ã„ã‚Œã°OK
            return hasattr(self, 'client') and self.client is not None
        except Exception:
            return False
    
    def _detect_language(self, text: str) -> Optional[str]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¨€èªã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        
        Args:
            text: åˆ†æã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            str: æ¨å®šã•ã‚ŒãŸè¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆ'ja', 'en', etc.ï¼‰
        """
        if not text:
            return None
        
        # æ—¥æœ¬èªæ–‡å­—ï¼ˆã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ï¼‰ã®æ¤œå‡º
        japanese_chars = 0
        total_chars = 0
        
        for char in text:
            if char.isalpha() or ord(char) > 127:  # éASCIIæ–‡å­—
                total_chars += 1
                # æ—¥æœ¬èªæ–‡å­—ã®ç¯„å›²ã‚’ãƒã‚§ãƒƒã‚¯
                char_code = ord(char)
                if (0x3040 <= char_code <= 0x309F or  # ã²ã‚‰ãŒãª
                    0x30A0 <= char_code <= 0x30FF or  # ã‚«ã‚¿ã‚«ãƒŠ
                    0x4E00 <= char_code <= 0x9FAF):   # æ¼¢å­—
                    japanese_chars += 1
        
        if total_chars == 0:
            return None
        
        # æ—¥æœ¬èªæ–‡å­—ã®å‰²åˆãŒ30%ä»¥ä¸Šãªã‚‰æ—¥æœ¬èªã¨åˆ¤å®š
        japanese_ratio = japanese_chars / total_chars
        if japanese_ratio >= 0.3:
            return "ja"
        else:
            return "en" 