"""
ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å®Ÿè£…
é–‹ç™ºç’°å¢ƒç”¨ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
"""
import os
import json
import shutil
import asyncio
from typing import Dict, List, Optional, BinaryIO, Union
from uuid import UUID, uuid4
from datetime import datetime
from pathlib import Path

from app.core.settings import settings
from app.providers.storage.base import StorageProvider


class LocalStorageProvider(StorageProvider):
    """
    ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
    é–‹ç™ºç’°å¢ƒç”¨
    """
    
    def __init__(self):
        """
        ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆæœŸåŒ–
        """
        # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        self.base_dir = Path(settings.LOCAL_STORAGE_PATH)
        self.chunks_dir = self.base_dir / "chunks"
        self.media_dir = self.base_dir / "media"
        self.metadata_dir = self.base_dir / "metadata"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        self.chunks_dir.mkdir(parents=True, exist_ok=True)
        self.media_dir.mkdir(parents=True, exist_ok=True)
        self.metadata_dir.mkdir(parents=True, exist_ok=True)
    
    def _get_user_dir(self, user_id: str) -> Path:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
        user_dir = self.media_dir / user_id
        user_dir.mkdir(exist_ok=True)
        return user_dir
    
    def _get_chunks_dir(self, user_id: str, media_id: str) -> Path:
        """ãƒãƒ£ãƒ³ã‚¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
        chunks_dir = self.chunks_dir / user_id / media_id
        chunks_dir.mkdir(parents=True, exist_ok=True)
        return chunks_dir
    
    def _get_metadata_path(self, user_id: str, media_id: str) -> Path:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—"""
        user_metadata_dir = self.metadata_dir / user_id
        user_metadata_dir.mkdir(parents=True, exist_ok=True)
        return user_metadata_dir / f"{media_id}.json"
    
    def _save_metadata(self, user_id: str, media_id: str, metadata: Dict) -> None:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        metadata_path = self._get_metadata_path(user_id, media_id)
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    def _load_metadata(self, user_id: str, media_id: str) -> Dict:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        metadata_path = self._get_metadata_path(user_id, media_id)
        if not metadata_path.exists():
            return {}
        
        with open(metadata_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _update_metadata(self, user_id: str, media_id: str, updates: Dict) -> Dict:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        metadata = self._load_metadata(user_id, media_id)
        metadata.update(updates)
        self._save_metadata(user_id, media_id, metadata)
        return metadata
    
    async def generate_upload_url(
        self, 
        media_id: Union[str, UUID], 
        file_type: str, 
        file_size: int,
        user_id: str,
        expires_in: int = 3600
    ) -> Dict:
        """
        ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ã®ç½²åä»˜ãURLã‚’ç”Ÿæˆ
        ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™
        """
        media_id_str = str(media_id)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã®å–å¾—
        ext = self._get_extension_from_mimetype(file_type)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        metadata = {
            "media_id": media_id_str,
            "user_id": user_id,
            "file_type": file_type,
            "file_size": file_size,
            "status": "pending",
            "progress": 0.0,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "filename": f"{media_id_str}.{ext}"
        }
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        self._save_metadata(user_id, media_id_str, metadata)
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ã‹ã©ã†ã‹ã®åˆ¤æ–­
        chunk_upload_enabled = file_size > settings.MAX_DIRECT_UPLOAD_SIZE
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ã€ã‚µãƒ¼ãƒãƒ¼ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLã‚’è¿”ã™
        base_url = settings.API_BASE_URL or "http://localhost:8000"
        
        if chunk_upload_enabled:
            # ãƒãƒ£ãƒ³ã‚¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ãªå ´åˆ
            return {
                "media_id": media_id_str,
                "upload_url": f"{base_url}/api/v1/media/test-upload/{media_id_str}",
                "chunk_upload_enabled": True,
                "max_chunk_size": settings.MAX_CHUNK_SIZE
            }
        else:
            # ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å ´åˆ
            return {
                "media_id": media_id_str,
                "upload_url": f"{base_url}/api/v1/media/test-upload/{media_id_str}",
                "chunk_upload_enabled": False,
                "max_chunk_size": settings.MAX_CHUNK_SIZE
            }
    
    async def upload_chunk(
        self,
        media_id: Union[str, UUID],
        chunk_index: int,
        total_chunks: int,
        chunk_data: BinaryIO,
        user_id: str
    ) -> Dict:
        """
        ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        """
        media_id_str = str(media_id)
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å–å¾—
        chunks_dir = self._get_chunks_dir(user_id, media_id_str)
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
        chunk_path = chunks_dir / f"chunk_{chunk_index:04d}.bin"
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        chunk_content = chunk_data.read()
        chunk_size = len(chunk_content)
        
        with open(chunk_path, 'wb') as f:
            f.write(chunk_content)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
        metadata = self._load_metadata(user_id, media_id_str)
        
        # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ã®è¿½åŠ 
        if "chunks" not in metadata:
            metadata["chunks"] = {}
        
        metadata["chunks"][str(chunk_index)] = {
            "size": chunk_size,
            "path": str(chunk_path),
            "uploaded_at": datetime.now().isoformat()
        }
        
        metadata["total_chunks"] = total_chunks
        metadata["updated_at"] = datetime.now().isoformat()
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é€²æ—ã®è¨ˆç®—
        uploaded_chunks = len(metadata["chunks"])
        metadata["upload_progress"] = uploaded_chunks / total_chunks
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        self._save_metadata(user_id, media_id_str, metadata)
        
        return {
            "media_id": media_id_str,
            "chunk_index": chunk_index,
            "received_bytes": chunk_size,
            "status": "success"
        }
    
    async def complete_upload(
        self,
        media_id: Union[str, UUID],
        total_chunks: int,
        total_size: int,
        md5_hash: Optional[str],
        user_id: str
    ) -> Dict:
        """
        ãƒãƒ£ãƒ³ã‚¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å®Œäº†å‡¦ç†
        """
        media_id_str = str(media_id)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        metadata = self._load_metadata(user_id, media_id_str)
        
        # ãƒãƒ£ãƒ³ã‚¯æ•°ã®ç¢ºèª
        if "chunks" not in metadata or len(metadata["chunks"]) != total_chunks:
            return {
                "media_id": media_id_str,
                "status": "error",
                "progress": 0.0,
                "error": f"ãƒãƒ£ãƒ³ã‚¯æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚æœŸå¾…: {total_chunks}, å®Ÿéš›: {len(metadata.get('chunks', {}))}"
            }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã®å–å¾—
        ext = self._get_extension_from_mimetype(metadata.get("file_type", "application/octet-stream"))
        
        # æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        user_dir = self._get_user_dir(user_id)
        final_path = user_dir / f"{media_id_str}.{ext}"
        
        # ãƒãƒ£ãƒ³ã‚¯ã®çµåˆ
        with open(final_path, 'wb') as outfile:
            for i in range(total_chunks):
                chunk_info = metadata["chunks"].get(str(i))
                if not chunk_info:
                    return {
                        "media_id": media_id_str,
                        "status": "error",
                        "progress": 0.0,
                        "error": f"ãƒãƒ£ãƒ³ã‚¯ {i} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                    }
                
                chunk_path = Path(chunk_info["path"])
                with open(chunk_path, 'rb') as infile:
                    outfile.write(infile.read())
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
        metadata["status"] = "processing"
        metadata["progress"] = 0.0
        metadata["file_path"] = str(final_path)
        metadata["updated_at"] = datetime.now().isoformat()
        
        if md5_hash:
            metadata["md5_hash"] = md5_hash
        
        self._save_metadata(user_id, media_id_str, metadata)
        
        # éåŒæœŸã§å‡¦ç†ã‚’é–‹å§‹ï¼ˆã“ã“ã§ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        asyncio.create_task(self._process_media(user_id, media_id_str))
        
        return {
            "media_id": media_id_str,
            "status": "processing",
            "progress": 0.0
        }
    
    async def _process_media(self, user_id: str, media_id: str) -> None:
        """
        ãƒ¡ãƒ‡ã‚£ã‚¢å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        å®Ÿéš›ã®ç’°å¢ƒã§ã¯ã€ã“ã“ã§STTã‚„OCRå‡¦ç†ã‚’è¡Œã†
        """
        # å‡¦ç†æ™‚é–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        total_steps = 5
        
        for step in range(1, total_steps + 1):
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
            metadata = self._load_metadata(user_id, media_id)
            metadata["progress"] = step / total_steps
            metadata["updated_at"] = datetime.now().isoformat()
            self._save_metadata(user_id, media_id, metadata)
            
            # å‡¦ç†æ™‚é–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            await asyncio.sleep(2)
        
        # å‡¦ç†å®Œäº†
        metadata = self._load_metadata(user_id, media_id)
        metadata["status"] = "completed"
        metadata["progress"] = 1.0
        metadata["updated_at"] = datetime.now().isoformat()
        metadata["result"] = {
            "transcript": "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®æ–‡å­—èµ·ã“ã—çµæœã§ã™ã€‚",
            "duration": 5.0,
            "language": "ja-JP"
        }
        self._save_metadata(user_id, media_id, metadata)
    
    async def get_media_status(
        self,
        media_id: Union[str, UUID],
        user_id: str
    ) -> Dict:
        """
        ãƒ¡ãƒ‡ã‚£ã‚¢å‡¦ç†çŠ¶æ³ã‚’å–å¾—
        """
        media_id_str = str(media_id)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        metadata = self._load_metadata(user_id, media_id_str)
        
        if not metadata:
            return {
                "media_id": media_id_str,
                "status": "error",
                "progress": 0.0,
                "error": "ãƒ¡ãƒ‡ã‚£ã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                "result": None
            }
        
        return {
            "media_id": media_id_str,
            "status": metadata.get("status", "unknown"),
            "progress": metadata.get("progress", 0.0),
            "error": metadata.get("error"),
            "result": metadata.get("result")
        }
    
    async def get_file_url(
        self,
        media_id: Union[str, UUID],
        user_id: str,
        expires_in: int = 3600
    ) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’å–å¾—
        ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™
        """
        media_id_str = str(media_id)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        metadata = self._load_metadata(user_id, media_id_str)
        
        if not metadata or "file_path" not in metadata:
            raise FileNotFoundError(f"ãƒ¡ãƒ‡ã‚£ã‚¢ {media_id_str} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ã€ã‚µãƒ¼ãƒãƒ¼ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLã‚’è¿”ã™
        base_url = settings.API_BASE_URL or "http://localhost:8000"
        return f"{base_url}/api/v1/media/download/{media_id_str}"
    
    async def delete_file(
        self,
        media_id: Union[str, UUID],
        user_id: str
    ) -> bool:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        """
        media_id_str = str(media_id)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        metadata = self._load_metadata(user_id, media_id_str)
        
        if not metadata:
            return False
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        if "file_path" in metadata:
            file_path = Path(metadata["file_path"])
            if file_path.exists():
                file_path.unlink()
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤
        chunks_dir = self._get_chunks_dir(user_id, media_id_str)
        if chunks_dir.exists():
            shutil.rmtree(chunks_dir)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        metadata_path = self._get_metadata_path(user_id, media_id_str)
        if metadata_path.exists():
            metadata_path.unlink()
        
        return True
    
    def _get_extension_from_mimetype(self, mimetype: str) -> str:
        """
        MIMEã‚¿ã‚¤ãƒ—ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’å–å¾—
        """
        mimetype_map = {
            "audio/wav": "wav",
            "audio/x-wav": "wav",
            "audio/wave": "wav",
            "audio/mp3": "mp3",
            "audio/mpeg": "mp3",
            "audio/m4a": "m4a",
            "audio/mp4": "m4a",
            "audio/aac": "aac",
            "audio/ogg": "ogg",
            "audio/webm": "webm",
            "application/pdf": "pdf",
            "image/jpeg": "jpg",
            "image/png": "png",
            "application/octet-stream": "bin"
        }
        
        return mimetype_map.get(mimetype.lower(), "bin")
    
    # ğŸ†• å†™çœŸã‚¹ã‚­ãƒ£ãƒ³å°‚ç”¨ãƒ¡ã‚½ãƒƒãƒ‰
    def _get_photo_scan_path(self, note_id: str, page_id: str) -> Path:
        """
        å†™çœŸã‚¹ã‚­ãƒ£ãƒ³ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
        å½¢å¼: {base_dir}/photo_scan/{note_id}/{page_id}.jpg
        """
        photo_scan_dir = self.base_dir / "photo_scan" / note_id
        photo_scan_dir.mkdir(parents=True, exist_ok=True)
        return photo_scan_dir / f"{page_id}.jpg"
    
    async def upload_photo_scan_image(
        self, 
        note_id: str, 
        page_id: str, 
        image_data: bytes, 
        user_id: str
    ) -> dict:
        """
        å†™çœŸã‚¹ã‚­ãƒ£ãƒ³ç”»åƒã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
        è¤‡æ•°ãƒšãƒ¼ã‚¸å¯¾å¿œã®ãŸã‚ note_id/page_id.jpg å½¢å¼ã§ä¿å­˜
        
        Args:
            note_id: ãƒãƒ¼ãƒˆID
            page_id: ãƒšãƒ¼ã‚¸ID
            image_data: ç”»åƒã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            
        Returns:
            ä¿å­˜çµæœã®è¾æ›¸
        """
        try:
            # å†™çœŸã‚¹ã‚­ãƒ£ãƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
            file_path = self._get_photo_scan_path(note_id, page_id)
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(file_path, 'wb') as f:
                f.write(image_data)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
            metadata = {
                "note_id": note_id,
                "page_id": page_id,
                "user_id": user_id,
                "file_type": "image/jpeg",
                "status": "completed",
                "file_path": str(file_path),
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "storage_type": "photo_scan"
            }
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆå†™çœŸã‚¹ã‚­ãƒ£ãƒ³ç”¨ï¼‰
            self._save_photo_scan_metadata(note_id, page_id, metadata)
            
            return {
                "status": "success",
                "note_id": note_id,
                "page_id": page_id,
                "file_path": str(file_path),
                "local_url": f"file://{file_path}"
            }
            
        except Exception as e:
            return {
                "status": "error",
                "note_id": note_id,
                "page_id": page_id,
                "error": f"ç”»åƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def _save_photo_scan_metadata(self, note_id: str, page_id: str, metadata: dict) -> None:
        """
        å†™çœŸã‚¹ã‚­ãƒ£ãƒ³ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
        """
        metadata_dir = self.metadata_dir / "photo_scan" / note_id
        metadata_dir.mkdir(parents=True, exist_ok=True)
        
        metadata_path = metadata_dir / f"{page_id}_metadata.json"
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    async def get_photo_scan_image_url(
        self,
        note_id: str,
        page_id: str,
        expires_in: int = 3600
    ) -> str:
        """
        å†™çœŸã‚¹ã‚­ãƒ£ãƒ³ç”»åƒã®ãƒ­ãƒ¼ã‚«ãƒ«URLã‚’å–å¾—
        """
        file_path = self._get_photo_scan_path(note_id, page_id)
        
        if file_path.exists():
            return f"file://{file_path}"
        else:
            raise FileNotFoundError(f"å†™çœŸã‚¹ã‚­ãƒ£ãƒ³ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {note_id}/{page_id}")
    
    async def delete_photo_scan_images(self, note_id: str) -> bool:
        """
        å†™çœŸã‚¹ã‚­ãƒ£ãƒ³ãƒãƒ¼ãƒˆã®å…¨ç”»åƒã‚’å‰Šé™¤
        """
        try:
            # note_id ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
            photo_scan_dir = self.base_dir / "photo_scan" / note_id
            if photo_scan_dir.exists():
                shutil.rmtree(photo_scan_dir)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚å‰Šé™¤
            metadata_dir = self.metadata_dir / "photo_scan" / note_id
            if metadata_dir.exists():
                shutil.rmtree(metadata_dir)
            
            return True
            
        except Exception as e:
            print(f"å†™çœŸã‚¹ã‚­ãƒ£ãƒ³ç”»åƒå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def upload_file(self, media_id: str, file: BinaryIO, filename: str, content_type: str, user_id: str) -> dict:
        """
        FormDataã§å—ã‘å–ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
        """
        ext = self._get_extension_from_mimetype(content_type)
        user_dir = self._get_user_dir(user_id)
        save_path = user_dir / f"{media_id}.{ext}"
        with open(save_path, 'wb') as out_file:
            import shutil
            shutil.copyfileobj(file, out_file)
        metadata = {
            "media_id": media_id,
            "user_id": user_id,
            "file_type": content_type,
            "status": "processing",
            "progress": 0.0,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "file_path": str(save_path)
        }
        self._save_metadata(user_id, media_id, metadata)
        asyncio.create_task(self._process_media(user_id, media_id))
        return {"status": "success", "media_id": media_id, "file_path": str(save_path)}
